<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ml3m.qa: Question Answering &mdash; ml3m  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ml3m.utils.openai: OpenAI-related utilities" href="ml3m.utils.openai.html" />
    <link rel="prev" title="ml3m.mcq: Multiple Choice Questions" href="ml3m.mcq.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ml3m
          </a>
              <div class="version">
                0.0.20
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../basics/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/generators.html">Generating Model Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/evaluators.html">Evaluating Model Performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="ml3m.base.html">ml3m.base</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml3m.errors.html">ml3m.errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml3m.mcq.html">ml3m.mcq</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ml3m.qa</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ml3m.qa.QaMetricEvaluator"><code class="docutils literal notranslate"><span class="pre">QaMetricEvaluator</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaMetricEvaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">QaMetricEvaluator.evaluate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaMetricEvaluator.load_avg_score"><code class="docutils literal notranslate"><span class="pre">QaMetricEvaluator.load_avg_score()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaMetricEvaluator.load_scores"><code class="docutils literal notranslate"><span class="pre">QaMetricEvaluator.load_scores()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ml3m.qa.QaOpenAIEvaluator"><code class="docutils literal notranslate"><span class="pre">QaOpenAIEvaluator</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaOpenAIEvaluator.evaluate"><code class="docutils literal notranslate"><span class="pre">QaOpenAIEvaluator.evaluate()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaOpenAIEvaluator.load_avg_score"><code class="docutils literal notranslate"><span class="pre">QaOpenAIEvaluator.load_avg_score()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ml3m.qa.QaOpenAIEvaluator.load_scores"><code class="docutils literal notranslate"><span class="pre">QaOpenAIEvaluator.load_scores()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ml3m.utils.openai.html">ml3m.utils.openai</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ml3m</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ml3m.qa: Question Answering</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/modules/ml3m.qa.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-ml3m.qa">
<span id="ml3m-qa-question-answering"></span><h1>ml3m.qa: Question Answering<a class="headerlink" href="#module-ml3m.qa" title="Permalink to this heading">ÔÉÅ</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="ml3m.qa.QaMetricEvaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ml3m.qa.</span></span><span class="sig-name descname"><span class="pre">QaMetricEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">DataItemType</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.11)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DatasetFormat</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'jsonl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bleu_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LoggingMode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ml3m/qa/eval.html#QaMetricEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ml3m.qa.QaMetricEvaluator" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="ml3m.base.html#ml3m.base.BaseEvaluator" title="ml3m.base.eval.BaseEvaluator"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseEvaluator</span></code></a></p>
<p>Evaluator for question-answering via common metrics.</p>
<p>This evaluator supports using the following metric to compare the actual response
with the reference answer:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/BLEU">BLEU-k</a> (BiLingual Evaluation Understudy)</p></li>
</ul>
<section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading">ÔÉÅ</a></h2>
<dl class="simple">
<dt>dataset<span class="classifier">str or pathlib.Path</span></dt><dd><p>The absolute path to the evaluation dataset.</p>
</dd>
<dt>save_path<span class="classifier">str or pathlib.Path</span></dt><dd><p>The absolute path to the save location. This path may or may not exist, and if
it exists, its file contents will be treated as a (partially) written result.
Whether to overwrite the existing results or to build on them depend on
<code class="docutils literal notranslate"><span class="pre">overwrite</span></code> when using the <a class="reference internal" href="#ml3m.qa.QaMetricEvaluator.evaluate" title="ml3m.qa.QaMetricEvaluator.evaluate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">QaMetricEvaluator.evaluate()</span></code></a> method.</p>
</dd>
<dt>info_func<span class="classifier">Callable</span></dt><dd><p>The function that extracts the question, actual answer, and expected answer of
a data item. The input parameter should be a <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series" title="(in pandas v2.1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.Series</span></code></a>, a list, or
a dictionary, depending on <code class="docutils literal notranslate"><span class="pre">fmt</span></code> and the specific type of each data item. The
output should be a tuple of three strings, respectively the question, the actual
answer to that question, and the expected answer of that question. See the notes
for examples.</p>
</dd>
<dt>fmt<span class="classifier">{‚Äújsonl‚Äù, ‚Äújson‚Äù, ‚Äúcsv‚Äù}, default=‚Äùjsonl‚Äù</span></dt><dd><p>The format of <code class="docutils literal notranslate"><span class="pre">dataset</span></code>.</p>
</dd>
<dt>bleu_k<span class="classifier">list of int or None</span></dt><dd><p>The list of k-values used for BLEU-k. Must be positive. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, use k-
values 1 to 4.</p>
</dd>
<dt>logging_mode<span class="classifier">{‚Äúall‚Äù, ‚Äúfailed‚Äù, ‚Äúnone‚Äù}, default=‚Äùall‚Äù</span></dt><dd><p>The logging mode, whether to save the logs of all items, or only of failed
items, or save no log.</p>
</dd>
<dt>verbose<span class="classifier">int, default=0</span></dt><dd><p>The verbosity level of the processing. For negative levels, only a progress bar
will be displayed. For level 0, the errored items will also be displayed. For
positive levels, the all items will be displayed, and the verbosity level
determines the number of lines to display for the message of each item.</p>
</dd>
</dl>
</section>
<section id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Here are some examples of <code class="docutils literal notranslate"><span class="pre">info_func</span></code>:</p>
<p>Assume that <code class="docutils literal notranslate"><span class="pre">dataset</span></code> is in <code class="docutils literal notranslate"><span class="pre">.jsonl</span></code> format and each line is of the following
form: <code class="docutils literal notranslate"><span class="pre">{{&quot;instruction&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;input&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;output&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;history&quot;:</span> <span class="pre">[],</span>
<span class="pre">&quot;response&quot;:</span> <span class="pre">&quot;xxx&quot;}}</span></code>. Then <code class="docutils literal notranslate"><span class="pre">info_func</span></code> can be defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">info_func</span><span class="p">(</span><span class="n">data_item</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;instruction&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">question</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span>
</pre></div>
</div>
<p>Now assume that <code class="docutils literal notranslate"><span class="pre">dataset</span></code> is in <code class="docutils literal notranslate"><span class="pre">.csv</span></code> format with columns ‚Äúquestion‚Äù,
‚Äúanswer‚Äù, and ‚Äúresponse‚Äù. Then <code class="docutils literal notranslate"><span class="pre">info_func</span></code> can be defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">info_func</span><span class="p">(</span><span class="n">data_item</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[[</span><span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;answer&quot;</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">answer</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaMetricEvaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span></span><a class="headerlink" href="#ml3m.qa.QaMetricEvaluator.evaluate" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Evaluate the specified dataset.</p>
<section id="id1">
<h3>Parameters<a class="headerlink" href="#id1" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>overwrite<span class="classifier">bool, default=False</span></dt><dd><p>Whether to overwrite the data in <code class="docutils literal notranslate"><span class="pre">save_path</span></code>. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the
evaluation will be built upon existing data in <code class="docutils literal notranslate"><span class="pre">save_path</span></code>, otherwise
all data will be evaluated are existing data will be overwritten.</p>
</dd>
</dl>
</section>
<section id="returns">
<h3>Returns<a class="headerlink" href="#returns" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>completed<span class="classifier">bool</span></dt><dd><p>Whether the task has been completed.</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaMetricEvaluator.load_avg_score">
<span class="sig-name descname"><span class="pre">load_avg_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subject_subset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.11)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/numbers.html#numbers.Real" title="(in Python v3.11)"><span class="pre">numbers.Real</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ml3m.qa.QaMetricEvaluator.load_avg_score" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Load the average score of each subject from the save location.</p>
<section id="id2">
<h3>Parameters<a class="headerlink" href="#id2" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>subject_subset<span class="classifier">list or None</span></dt><dd><p>The subjects of the scores to select, i.e., the columns. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
select all subjects.</p>
</dd>
<dt>items<span class="classifier">list or None</span></dt><dd><p>The indices of the items to select. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, select all items. This
will be applied after <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>. This does not necessarily need
to be a subset of the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>. However,
any item out of range would not be taken into account when computing the
average score.</p>
</dd>
</dl>
</section>
<section id="id3">
<h3>Returns<a class="headerlink" href="#id3" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>avg_score<span class="classifier">pandas.DataFrame</span></dt><dd><p>The average score loaded from <code class="docutils literal notranslate"><span class="pre">save_path</span></code>.</p>
</dd>
</dl>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Suppose that the file at <code class="docutils literal notranslate"><span class="pre">save_path</span></code> looks like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span><span class="n">score1</span><span class="p">,</span><span class="n">score2</span>
<span class="mi">0</span><span class="p">,</span><span class="mi">78</span><span class="p">,</span><span class="mi">83</span>
<span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">76</span>
<span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">92</span>
<span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">38</span>
<span class="mi">4</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">()</span>  
<span class="go">{&#39;score1&#39;: 60.0, &#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">(</span><span class="n">subject_subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score2&quot;</span><span class="p">])</span>  
<span class="go">{&#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)))</span>  
<span class="go">{&#39;score1&#39;: 60.0, &#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaMetricEvaluator.load_scores">
<span class="sig-name descname"><span class="pre">load_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subject_subset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v2.1.0)"><span class="pre">DataFrame</span></a></span></span><a class="headerlink" href="#ml3m.qa.QaMetricEvaluator.load_scores" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Load the scores from the save location.</p>
<section id="id4">
<h3>Parameters<a class="headerlink" href="#id4" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>subject_subset<span class="classifier">list or None</span></dt><dd><p>The subjects of the scores to select, i.e., the columns. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
select all subjects. In the returned <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>, the columns
will be in the same order as <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>.</p>
</dd>
<dt>items<span class="classifier">list or None</span></dt><dd><p>The indices of the items to select. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, select all items. This
will be applied after <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>. This does not necessarily need
to be a subset of the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>. The
indices that do not exist in the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>
will be assigned <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. In the returned <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>, the rows
will be in the same order as <code class="docutils literal notranslate"><span class="pre">items</span></code>.</p>
</dd>
</dl>
</section>
<section id="id5">
<h3>Returns<a class="headerlink" href="#id5" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>scores<span class="classifier">pandas.DataFrame</span></dt><dd><p>The scores loaded from <code class="docutils literal notranslate"><span class="pre">save_path</span></code>.</p>
</dd>
</dl>
</section>
<section id="id6">
<h3>Examples<a class="headerlink" href="#id6" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Suppose that the file at <code class="docutils literal notranslate"><span class="pre">save_path</span></code> looks like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span><span class="n">score1</span><span class="p">,</span><span class="n">score2</span>
<span class="mi">0</span><span class="p">,</span><span class="mi">78</span><span class="p">,</span><span class="mi">83</span>
<span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">76</span>
<span class="mi">3</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">92</span>
<span class="mi">4</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">38</span>
<span class="mi">5</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">()</span>  
<span class="go">   score1  score2</span>
<span class="go">i</span>
<span class="go">0      78      83</span>
<span class="go">1      64      76</span>
<span class="go">3     100      92</span>
<span class="go">4      28      38</span>
<span class="go">5      30      45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">(</span><span class="n">subject_subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score2&quot;</span><span class="p">])</span>  
<span class="go">   score2</span>
<span class="go">i</span>
<span class="go">0      83</span>
<span class="go">1      76</span>
<span class="go">3      92</span>
<span class="go">4      38</span>
<span class="go">5      45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)))</span>  
<span class="go">   score1  score2</span>
<span class="go">i</span>
<span class="go">0    78.0    83.0</span>
<span class="go">1    64.0    76.0</span>
<span class="go">2     NaN     NaN</span>
<span class="go">3   100.0    92.0</span>
<span class="go">4    28.0    38.0</span>
<span class="go">5    30.0    45.0</span>
<span class="go">6     NaN     NaN</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ml3m.qa.QaOpenAIEvaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ml3m.qa.</span></span><span class="sig-name descname"><span class="pre">QaOpenAIEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">openai_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">DataItemType</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.11)"><span class="pre">tuple</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DatasetFormat</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'jsonl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">domain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aspects</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aspect_descriptions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.11)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timeout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">60</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpt-3.5-turbo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LoggingMode</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ml3m/qa/eval.html#QaOpenAIEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#ml3m.qa.QaOpenAIEvaluator" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Bases: <a class="reference internal" href="ml3m.base.html#ml3m.base.BaseOpenAIEvaluator" title="ml3m.base.eval.BaseOpenAIEvaluator"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseOpenAIEvaluator</span></code></a></p>
<p>Evaluator for question-answering via OpenAI.</p>
<p>This evaluator utilizes the ability of OpenAI models to tell the quality of a
response from the following aspects:</p>
<ul class="simple">
<li><p><strong>Accuracy</strong>: Using the reference answer as the ground truth, does the response
include factually incorrect information?</p></li>
<li><p><strong>Completeness</strong>: Compared with the reference answer, is the response missing
details?</p></li>
<li><p><strong>Clarity</strong>: Is the response well-organized and clearly presented? If accuracy
and completeness is poor, clarity should also be considered poor.</p></li>
</ul>
<section id="id7">
<h2>Parameters<a class="headerlink" href="#id7" title="Permalink to this heading">ÔÉÅ</a></h2>
<dl class="simple">
<dt>dataset<span class="classifier">str or pathlib.Path</span></dt><dd><p>The absolute path to the evaluation dataset.</p>
</dd>
<dt>save_path<span class="classifier">str or pathlib.Path</span></dt><dd><p>The absolute path to the save location. This path may or may not exist, and if
it exists, its file contents will be treated as a (partially) written result.
Whether to overwrite the existing results or to build on them depend on
<code class="docutils literal notranslate"><span class="pre">overwrite</span></code> when using the <a class="reference internal" href="#ml3m.qa.QaOpenAIEvaluator.evaluate" title="ml3m.qa.QaOpenAIEvaluator.evaluate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">QaOpenAIEvaluator.evaluate()</span></code></a> method.</p>
</dd>
<dt>openai_config<span class="classifier">str or pathlib.Path</span></dt><dd><p>The absolute path to the OpenAI configuration file.</p>
</dd>
<dt>info_func<span class="classifier">Callable</span></dt><dd><p>The function that extracts the question, actual answer, and expected answer of
a data item. The input parameter should be a <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series" title="(in pandas v2.1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.Series</span></code></a>, a list, or
a dictionary, depending on <code class="docutils literal notranslate"><span class="pre">fmt</span></code> and the specific type of each data item. The
output should be a tuple of three strings, respectively the question, the actual
answer to that question, and the expected answer of that question. See the notes
for examples.</p>
</dd>
<dt>fmt<span class="classifier">{‚Äújsonl‚Äù, ‚Äújson‚Äù, ‚Äúcsv‚Äù}, default=‚Äùjsonl‚Äù</span></dt><dd><p>The format of <code class="docutils literal notranslate"><span class="pre">dataset</span></code>.</p>
</dd>
<dt>domain<span class="classifier">str, optional</span></dt><dd><p>The domain of knowledge. ChatGPT will be prompted to know that your question,
answer, and reference answer are ‚Äúin {domain}‚Äù. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then this
information will not be given to ChatGPT.</p>
</dd>
<dt>aspects<span class="classifier">list of str, optional</span></dt><dd><p>The aspects to evaluate. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, evalute accuracy, completeness, and
clarity. If there is any string other than ‚Äúaccuracy‚Äù, ‚Äúcompleteness‚Äù, and
‚Äúclarity‚Äù, then they have to be specified in <code class="docutils literal notranslate"><span class="pre">aspect_descriptions</span></code>.</p>
</dd>
<dt>aspect_descriptions<span class="classifier">dict, optional</span></dt><dd><p>An optional dictionary mapping aspects to their descriptions. ‚Äúaccuracy‚Äù,
‚Äúcompleteness‚Äù, and ‚Äúclarity‚Äù have default descriptions but can also be
overridden by this parameter. Any other aspect, if used in <code class="docutils literal notranslate"><span class="pre">aspects</span></code>, must
exist as a key here.</p>
</dd>
<dt>n_iter<span class="classifier">int, default=3</span></dt><dd><p>The number of iterations for each data item. The mean of the scores for each
data item will be taken as the final score.</p>
</dd>
<dt>timeout<span class="classifier">float, default=60</span></dt><dd><p>The timeout in seconds. This is not the OpenAI timeout, but the timeout for
cancelling the worker tasks.</p>
</dd>
<dt>model<span class="classifier">str, default=‚Äùgpt-3.5-turbo‚Äù</span></dt><dd><p>The ID of the model to use, must be one of the available OpenAI models that
support the ChatCompletion API. See also
<a class="reference external" href="https://platform.openai.com/docs/models/model-endpoint-compatibility">https://platform.openai.com/docs/models/model-endpoint-compatibility</a></p>
</dd>
<dt>logging_mode<span class="classifier">{‚Äúall‚Äù, ‚Äúfailed‚Äù, ‚Äúnone‚Äù}, default=‚Äùall‚Äù</span></dt><dd><p>The logging mode, whether to save the logs of all items, or only of failed
items, or save no log.</p>
</dd>
<dt>verbose<span class="classifier">int, default=0</span></dt><dd><p>The verbosity level of the processing. For negative levels, only a progress bar
will be displayed. For level 0, the errored items will also be displayed. For
positive levels, the all items will be displayed, and the verbosity level
determines the number of lines to display for the message of each item.</p>
</dd>
</dl>
</section>
<section id="id8">
<h2>Notes<a class="headerlink" href="#id8" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Here are some examples of <code class="docutils literal notranslate"><span class="pre">info_func</span></code>:</p>
<p>Assume that <code class="docutils literal notranslate"><span class="pre">dataset</span></code> is in <code class="docutils literal notranslate"><span class="pre">.jsonl</span></code> format and each line is of the following
form: <code class="docutils literal notranslate"><span class="pre">{{&quot;instruction&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;input&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;output&quot;:</span> <span class="pre">&quot;xxx&quot;,</span> <span class="pre">&quot;history&quot;:</span> <span class="pre">[],</span>
<span class="pre">&quot;response&quot;:</span> <span class="pre">&quot;xxx&quot;}}</span></code>. Then <code class="docutils literal notranslate"><span class="pre">info_func</span></code> can be defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">info_func</span><span class="p">(</span><span class="n">data_item</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">question</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;instruction&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">]</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">question</span><span class="p">,</span> <span class="n">actual</span><span class="p">,</span> <span class="n">expected</span>
</pre></div>
</div>
<p>Now assume that <code class="docutils literal notranslate"><span class="pre">dataset</span></code> is in <code class="docutils literal notranslate"><span class="pre">.csv</span></code> format with columns ‚Äúquestion‚Äù,
‚Äúanswer‚Äù, and ‚Äúresponse‚Äù. Then <code class="docutils literal notranslate"><span class="pre">info_func</span></code> can be defined as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">info_func</span><span class="p">(</span><span class="n">data_item</span><span class="p">:</span> <span class="n">pandas</span><span class="o">.</span><span class="n">Series</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
    <span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">,</span> <span class="n">response</span> <span class="o">=</span> <span class="n">data_item</span><span class="p">[[</span><span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;answer&quot;</span><span class="p">,</span> <span class="s2">&quot;response&quot;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">question</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">answer</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaOpenAIEvaluator.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span></span><a class="headerlink" href="#ml3m.qa.QaOpenAIEvaluator.evaluate" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Evaluate the specified dataset.</p>
<section id="id9">
<h3>Parameters<a class="headerlink" href="#id9" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>overwrite<span class="classifier">bool, default=False</span></dt><dd><p>Whether to overwrite the data in <code class="docutils literal notranslate"><span class="pre">save_path</span></code>. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the
evaluation will be built upon existing data in <code class="docutils literal notranslate"><span class="pre">save_path</span></code>, otherwise
all data will be evaluated are existing data will be overwritten.</p>
</dd>
</dl>
</section>
<section id="id10">
<h3>Returns<a class="headerlink" href="#id10" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>completed<span class="classifier">bool</span></dt><dd><p>Whether the task has been completed.</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaOpenAIEvaluator.load_avg_score">
<span class="sig-name descname"><span class="pre">load_avg_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subject_subset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.11)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/numbers.html#numbers.Real" title="(in Python v3.11)"><span class="pre">numbers.Real</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ml3m.qa.QaOpenAIEvaluator.load_avg_score" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Load the average score of each subject from the save location.</p>
<section id="id11">
<h3>Parameters<a class="headerlink" href="#id11" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>subject_subset<span class="classifier">list or None</span></dt><dd><p>The subjects of the scores to select, i.e., the columns. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
select all subjects.</p>
</dd>
<dt>items<span class="classifier">list or None</span></dt><dd><p>The indices of the items to select. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, select all items. This
will be applied after <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>. This does not necessarily need
to be a subset of the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>. However,
any item out of range would not be taken into account when computing the
average score.</p>
</dd>
</dl>
</section>
<section id="id12">
<h3>Returns<a class="headerlink" href="#id12" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>avg_score<span class="classifier">pandas.DataFrame</span></dt><dd><p>The average score loaded from <code class="docutils literal notranslate"><span class="pre">save_path</span></code>.</p>
</dd>
</dl>
</section>
<section id="id13">
<h3>Examples<a class="headerlink" href="#id13" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Suppose that the file at <code class="docutils literal notranslate"><span class="pre">save_path</span></code> looks like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span><span class="n">score1</span><span class="p">,</span><span class="n">score2</span>
<span class="mi">0</span><span class="p">,</span><span class="mi">78</span><span class="p">,</span><span class="mi">83</span>
<span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">76</span>
<span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">92</span>
<span class="mi">3</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">38</span>
<span class="mi">4</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">()</span>  
<span class="go">{&#39;score1&#39;: 60.0, &#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">(</span><span class="n">subject_subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score2&quot;</span><span class="p">])</span>  
<span class="go">{&#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_avg_score</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)))</span>  
<span class="go">{&#39;score1&#39;: 60.0, &#39;score2&#39;: 66.8}</span>
</pre></div>
</div>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ml3m.qa.QaOpenAIEvaluator.load_scores">
<span class="sig-name descname"><span class="pre">load_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subject_subset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">items</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v2.1.0)"><span class="pre">DataFrame</span></a></span></span><a class="headerlink" href="#ml3m.qa.QaOpenAIEvaluator.load_scores" title="Permalink to this definition">ÔÉÅ</a></dt>
<dd><p>Load the scores from the save location.</p>
<section id="id14">
<h3>Parameters<a class="headerlink" href="#id14" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>subject_subset<span class="classifier">list or None</span></dt><dd><p>The subjects of the scores to select, i.e., the columns. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
select all subjects. In the returned <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>, the columns
will be in the same order as <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>.</p>
</dd>
<dt>items<span class="classifier">list or None</span></dt><dd><p>The indices of the items to select. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, select all items. This
will be applied after <code class="docutils literal notranslate"><span class="pre">subject_subset</span></code>. This does not necessarily need
to be a subset of the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>. The
indices that do not exist in the index of the loaded <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>
will be assigned <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. In the returned <code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code>, the rows
will be in the same order as <code class="docutils literal notranslate"><span class="pre">items</span></code>.</p>
</dd>
</dl>
</section>
<section id="id15">
<h3>Returns<a class="headerlink" href="#id15" title="Permalink to this heading">ÔÉÅ</a></h3>
<dl class="simple">
<dt>scores<span class="classifier">pandas.DataFrame</span></dt><dd><p>The scores loaded from <code class="docutils literal notranslate"><span class="pre">save_path</span></code>.</p>
</dd>
</dl>
</section>
<section id="id16">
<h3>Examples<a class="headerlink" href="#id16" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Suppose that the file at <code class="docutils literal notranslate"><span class="pre">save_path</span></code> looks like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span><span class="n">score1</span><span class="p">,</span><span class="n">score2</span>
<span class="mi">0</span><span class="p">,</span><span class="mi">78</span><span class="p">,</span><span class="mi">83</span>
<span class="mi">1</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">76</span>
<span class="mi">3</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">92</span>
<span class="mi">4</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">38</span>
<span class="mi">5</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">()</span>  
<span class="go">   score1  score2</span>
<span class="go">i</span>
<span class="go">0      78      83</span>
<span class="go">1      64      76</span>
<span class="go">3     100      92</span>
<span class="go">4      28      38</span>
<span class="go">5      30      45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">(</span><span class="n">subject_subset</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score2&quot;</span><span class="p">])</span>  
<span class="go">   score2</span>
<span class="go">i</span>
<span class="go">0      83</span>
<span class="go">1      76</span>
<span class="go">3      92</span>
<span class="go">4      38</span>
<span class="go">5      45</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">evaluator</span><span class="o">.</span><span class="n">load_scores</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">7</span><span class="p">)))</span>  
<span class="go">   score1  score2</span>
<span class="go">i</span>
<span class="go">0    78.0    83.0</span>
<span class="go">1    64.0    76.0</span>
<span class="go">2     NaN     NaN</span>
<span class="go">3   100.0    92.0</span>
<span class="go">4    28.0    38.0</span>
<span class="go">5    30.0    45.0</span>
<span class="go">6     NaN     NaN</span>
</pre></div>
</div>
</section>
</dd></dl>

</section>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ml3m.mcq.html" class="btn btn-neutral float-left" title="ml3m.mcq: Multiple Choice Questions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ml3m.utils.openai.html" class="btn btn-neutral float-right" title="ml3m.utils.openai: OpenAI-related utilities" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Yao Xiao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>